{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#all imports here\nimport numpy as np\nimport pandas as pd\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\nimport time\nimport cv2\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport shutil\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import datasets, layers, models\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-26T13:31:04.005638Z","iopub.execute_input":"2022-05-26T13:31:04.006043Z","iopub.status.idle":"2022-05-26T13:31:06.737236Z","shell.execute_reply.started":"2022-05-26T13:31:04.006004Z","shell.execute_reply":"2022-05-26T13:31:06.735961Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#info about classes\nhand_ges=r'../input/2000-hand-gestures/images'\nclasslist=sorted(os.listdir(hand_ges))\nprint (classlist)\nfilepaths = []\nlabels=[] \nfor classes in classlist:\n    classpath=os.path.join(hand_ges, classes)\n    flist=sorted(os.listdir(classpath))\n    for f in flist:\n        fpath=os.path.join(classpath,f)\n        filepaths.append(fpath)\n        labels.append(classes)\nFseries=pd.Series(filepaths, name='filepaths')\nLseries=pd.Series(labels, name='labels')        \ndf=pd.concat([Fseries, Lseries], axis=1)\ntrain_df, dummy_df=train_test_split(df, train_size=.85, shuffle=True, random_state=123, stratify=df['labels'])\nvalid_df, test_df= train_test_split(dummy_df, train_size=.5, shuffle=True, random_state=123, stratify=dummy_df['labels'])     \n\nclasses=sorted(list(train_df['labels'].unique()))\nclass_count = len(classes)\nprint('The number of classes in the dataset is: ', class_count)\ngroups=train_df.groupby('labels')\nprint('{0:^30s} {1:^13s}'.format('CLASS', 'NO. OF IMAGES'))\ncountlist=[]\nclasslist=[]\nfor label in sorted(list(train_df['labels'].unique())):\n    group=groups.get_group(label)\n    countlist.append(len(group))\n    classlist.append(label)\n    print('{0:^30s} {1:^13s}'.format(label, str(len(group))))","metadata":{"execution":{"iopub.status.busy":"2022-05-26T13:31:06.739237Z","iopub.execute_input":"2022-05-26T13:31:06.739960Z","iopub.status.idle":"2022-05-26T13:31:06.782863Z","shell.execute_reply.started":"2022-05-26T13:31:06.739926Z","shell.execute_reply":"2022-05-26T13:31:06.781911Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#trim dataset to offset misbalanced data in train_df\ndef trim(df, max_samples, min_samples, column):\n    df=df.copy()\n    groups=df.groupby(column)    \n    trimmed_df = pd.DataFrame(columns = df.columns)\n    groups=df.groupby(column)\n    for label in df[column].unique(): \n        group=groups.get_group(label)\n        count=len(group)    \n        if count > max_samples:\n            sampled_group=group.sample(n=max_samples, random_state=123,axis=0)\n            trimmed_df=pd.concat([trimmed_df, sampled_group], axis=0)\n        else:\n            if count>=min_samples:\n                sampled_group=group        \n                trimmed_df=pd.concat([trimmed_df, sampled_group], axis=0)\n    return trimmed_df\n\nmax_samples=200\nmin_samples=0\ncolumn='labels'\ntrain_df=trim(train_df, max_samples, min_samples, column)","metadata":{"execution":{"iopub.status.busy":"2022-05-26T13:31:06.784116Z","iopub.execute_input":"2022-05-26T13:31:06.784482Z","iopub.status.idle":"2022-05-26T13:31:06.808091Z","shell.execute_reply.started":"2022-05-26T13:31:06.784446Z","shell.execute_reply":"2022-05-26T13:31:06.807152Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#balancing dataset\ndef balance(df, n, working_dir, img_size):\n    def augment(df,n, working_dir, img_size):\n        aug_dir=os.path.join(working_dir, 'aug')\n        os.mkdir(aug_dir)        \n        for label in df['labels'].unique():    \n            dir_path=os.path.join(aug_dir,label)    \n            os.mkdir(dir_path)\n        #create and store augmented images  \n        total=0\n        gen=ImageDataGenerator(horizontal_flip=True,  rotation_range=20, width_shift_range=.2,\n                                      height_shift_range=.2, zoom_range=.2)\n        groups=df.groupby('labels') \n        for label in df['labels'].unique():                 \n            group=groups.get_group(label)   \n            sample_count=len(group)     \n            if sample_count< n:\n                aug_img_count=0\n                delta=n - sample_count\n                target_dir=os.path.join(aug_dir, label) \n                msg='{0:40s} for class {1:^30s} creating {2:^5s} augmented images'.format(' ', label, str(delta))\n                print(msg, '\\r', end='') # prints over on the same line\n                aug_gen=gen.flow_from_dataframe( group,  x_col='filepaths', y_col=None, target_size=img_size,\n                                                class_mode=None, batch_size=1, shuffle=False, \n                                                save_to_dir=target_dir, save_prefix='aug-', color_mode='rgb',\n                                                save_format='jpg')\n                while aug_img_count<delta:\n                    images=next(aug_gen)            \n                    aug_img_count += len(images)\n                total +=aug_img_count\n        print('Total Augmented images created= ', total)\n        \n        #create aug_df and merge with train_df to create composite training set ndf\n        aug_fpaths=[]\n        aug_labels=[]\n        classlist=os.listdir(aug_dir)\n        for klass in classlist:\n            classpath=os.path.join(aug_dir, klass)     \n            flist=os.listdir(classpath)    \n            for f in flist:        \n                fpath=os.path.join(classpath,f)         \n                aug_fpaths.append(fpath)\n                aug_labels.append(klass)\n                \n        Fseries=pd.Series(aug_fpaths, name='filepaths')\n        Lseries=pd.Series(aug_labels, name='labels')\n        aug_df=pd.concat([Fseries, Lseries], axis=1)        \n        df=pd.concat([df,aug_df], axis=0).reset_index(drop=True)\n        return df \n    \n    df=df.copy() \n    \n    #make directories to store augmented images\n    aug_dir=os.path.join(working_dir, 'aug')    \n    if 'aug' in os.listdir(working_dir):\n        print(' Augmented images already exist. Enter U to use these images', flush=True)\n        ans=input(' ')\n        if ans != 'U' or ans != 'u':            \n            shutil.rmtree(aug_dir) #start with an clean empty directory  \n            augment(df,n, working_dir, img_size)\n            return df\n        else:\n            \n            return df\n    else:\n        augment(df,n, working_dir, img_size)\n        return df\n    \nn=200 \nworking_dir=r'./' \nimg_size=(200,160) #size of augmented images\ntrain_df=balance(train_df, n, working_dir, img_size)","metadata":{"execution":{"iopub.status.busy":"2022-05-26T13:31:06.810601Z","iopub.execute_input":"2022-05-26T13:31:06.811285Z","iopub.status.idle":"2022-05-26T13:31:13.263455Z","shell.execute_reply.started":"2022-05-26T13:31:06.811143Z","shell.execute_reply":"2022-05-26T13:31:13.262244Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#creating test samples\nbatch_size=30 \ntrgen=ImageDataGenerator(horizontal_flip=True,rotation_range=20, width_shift_range=.2,\n                                  height_shift_range=.2, zoom_range=.2 )\nt_and_v_gen=ImageDataGenerator()\nmsg='{0:70s} for train generator'.format(' ')\nprint(msg, '\\r', end='') \ntrain_gen=trgen.flow_from_dataframe(train_df, x_col='filepaths', y_col='labels',\n                                   class_mode='categorical', color_mode='rgb', shuffle=True, batch_size=batch_size)\nmsg='{0:70s} for valid generator'.format(' ')\nprint(msg, '\\r', end='') \nvalid_gen=t_and_v_gen.flow_from_dataframe(valid_df, x_col='filepaths', y_col='labels',\n                                   class_mode='categorical', color_mode='rgb', shuffle=False, batch_size=batch_size)\nlength=len(test_df)\ntest_batch_size=sorted([int(length/n) for n in range(1,length+1) if length % n ==0 and length/n<=80],reverse=True)[0]  \ntest_steps=int(length/test_batch_size)\nmsg='{0:70s} for test generator'.format(' ')\nprint(msg, '\\r', end='') \ntest_gen=t_and_v_gen.flow_from_dataframe(test_df, x_col='filepaths', y_col='labels',\n                                   class_mode='categorical', color_mode='rgb', shuffle=False, batch_size=test_batch_size)\nclasses=list(train_gen.class_indices.keys())\nclass_indices=list(train_gen.class_indices.values())\nclass_count=len(classes)\nlabels=test_gen.labels\nprint ( 'test batch size: ' ,test_batch_size, '  test steps: ', test_steps, ' number of classes : ', class_count)","metadata":{"execution":{"iopub.status.busy":"2022-05-26T13:31:13.264986Z","iopub.execute_input":"2022-05-26T13:31:13.265455Z","iopub.status.idle":"2022-05-26T13:31:14.254529Z","shell.execute_reply.started":"2022-05-26T13:31:13.265394Z","shell.execute_reply":"2022-05-26T13:31:14.253250Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#sample test images\ndef showSampleImg(gen):\n    t_dict=gen.class_indices\n    classes=list(t_dict.keys())    \n    images,labels=next(gen) \n    plt.figure(figsize=(10, 10))\n    length=len(labels)\n    if length<15:   #show max 15 images\n        r=length\n    else:\n        r=25\n    for i in range(r):        \n        plt.subplot(5, 5, i + 1)\n        image=images[i] /255       \n        plt.imshow(image)\n        index=np.argmax(labels[i])\n        class_name=classes[index]\n        plt.title(class_name, color='black', fontsize=10)\n        plt.axis('off')\n    plt.show()\n    \nshowSampleImg(train_gen)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-26T13:31:14.256603Z","iopub.execute_input":"2022-05-26T13:31:14.257358Z","iopub.status.idle":"2022-05-26T13:31:17.042153Z","shell.execute_reply.started":"2022-05-26T13:31:14.257303Z","shell.execute_reply":"2022-05-26T13:31:17.041405Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#creating model using attention based CNN EfficientNetB5\nimg_shape=(img_size[0], img_size[1], 3)\nmodel_name='EfficientNetB5'\nbase_model=tf.keras.applications.efficientnet.EfficientNetB5(include_top=False, weights=\"imagenet\",input_shape=img_shape, pooling='max') \nbase_model.trainable=True\nx=base_model.output\nx=BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\nx = Dense(256, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n                bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\nx=Dropout(rate=.4, seed=123)(x)       \noutput=Dense(class_count, activation='softmax')(x)\nmodel=Model(inputs=base_model.input, outputs=output)\nlr=.001 #starting learning rate\nmodel.compile(Adamax(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy']) ","metadata":{"execution":{"iopub.status.busy":"2022-05-26T13:31:17.043346Z","iopub.execute_input":"2022-05-26T13:31:17.043848Z","iopub.status.idle":"2022-05-26T13:31:22.141653Z","shell.execute_reply.started":"2022-05-26T13:31:17.043812Z","shell.execute_reply":"2022-05-26T13:31:22.140779Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"epochs=10 #can change it to 20, i kept it as 10 because it was taking too long to train and i ran out of ram storage\nrlronp=tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2,verbose=1)\nestop=tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=4, verbose=1,restore_best_weights=True)\ncallbacks=[rlronp, estop]\n\nhistory=model.fit(x=train_gen,  epochs=epochs, verbose=1, callbacks=callbacks,  validation_data=valid_gen,\n               validation_steps=None,  shuffle=False,  initial_epoch=0)","metadata":{"execution":{"iopub.status.busy":"2022-05-26T13:31:22.142842Z","iopub.execute_input":"2022-05-26T13:31:22.143303Z","iopub.status.idle":"2022-05-26T15:14:37.459097Z","shell.execute_reply.started":"2022-05-26T13:31:22.143261Z","shell.execute_reply":"2022-05-26T15:14:37.458170Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#to plot training data\ndef tr_plot(tr_data, start_epoch):\n    #plot the training and validation data\n    tacc=tr_data.history['accuracy']\n    tloss=tr_data.history['loss']\n    vacc=tr_data.history['val_accuracy']\n    vloss=tr_data.history['val_loss']\n    Epoch_count=len(tacc)+ start_epoch\n    Epochs=[]\n    for i in range (start_epoch ,Epoch_count):\n        Epochs.append(i+1)   \n    index_loss=np.argmin(vloss)\n    val_lowest=vloss[index_loss]\n    index_acc=np.argmax(vacc)\n    acc_highest=vacc[index_acc]\n    plt.style.use('fivethirtyeight')\n    sc_label='best epoch= '+ str(index_loss+1 +start_epoch)\n    vc_label='best epoch= '+ str(index_acc + 1+ start_epoch)\n    fig,axes=plt.subplots(nrows=1, ncols=2, figsize=(20,8))\n    axes[0].plot(Epochs,tloss, 'r', label='Training loss')\n    axes[0].plot(Epochs,vloss,'g',label='Validation loss' )\n    axes[0].scatter(index_loss+1 +start_epoch,val_lowest, s=150, c= 'blue', label=sc_label)\n    axes[0].set_title('Training and Validation Loss')\n    axes[0].set_xlabel('Epochs')\n    axes[0].set_ylabel('Loss')\n    axes[0].legend()\n    axes[1].plot (Epochs,tacc,'r',label= 'Training Accuracy')\n    axes[1].plot (Epochs,vacc,'g',label= 'Validation Accuracy')\n    axes[1].scatter(index_acc+1 +start_epoch,acc_highest, s=150, c= 'blue', label=vc_label)\n    axes[1].set_title('Training and Validation Accuracy')\n    axes[1].set_xlabel('Epochs')\n    axes[1].set_ylabel('Accuracy')\n    axes[1].legend()\n    plt.tight_layout    \n    plt.show()\n    \ntr_plot(history,0)","metadata":{"execution":{"iopub.status.busy":"2022-05-26T15:14:37.460632Z","iopub.execute_input":"2022-05-26T15:14:37.461781Z","iopub.status.idle":"2022-05-26T15:14:38.015236Z","shell.execute_reply.started":"2022-05-26T15:14:37.461737Z","shell.execute_reply":"2022-05-26T15:14:38.014102Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#to predict and print confusion matrix and f-score\ndef predictor(test_gen, test_steps):\n    y_pred= []\n    y_true=test_gen.labels\n    classes=list(train_gen.class_indices.keys())\n    class_count=len(classes)\n    errors=0\n    preds=model.predict(test_gen, steps=test_steps, verbose=1) \n    tests=len(preds)\n    for i, p in enumerate(preds):\n            pred_index=np.argmax(p)         \n            true_index=test_gen.labels[i] \n            if pred_index != true_index: #check if a misclassification has occurred                                           \n                errors=errors + 1\n            y_pred.append(pred_index)\n    acc=( 1-errors/tests) * 100\n    print(f'there were {errors} in {tests} tests for an accuracy of {acc:6.2f}')\n    ypred=np.array(y_pred)\n    ytrue=np.array(y_true)\n    if class_count <=30:\n        cm = confusion_matrix(ytrue, ypred )\n        # plot the confusion matrix\n        plt.figure(figsize=(10, 6))\n        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)       \n        plt.xticks(np.arange(class_count)+.5, classes, rotation=90)\n        plt.yticks(np.arange(class_count)+.5, classes, rotation=0)\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"Actual\")\n        plt.title(\"Confusion Matrix\")\n        plt.show()\n    clr = classification_report(y_true, y_pred, target_names=classes, digits= 4) \n    print(\"Classification Report:\\n----------------------\\n\", clr)\n    return errors, tests\nerrors, tests=predictor(test_gen, test_steps)","metadata":{"execution":{"iopub.status.busy":"2022-05-26T15:17:27.539682Z","iopub.execute_input":"2022-05-26T15:17:27.540702Z","iopub.status.idle":"2022-05-26T15:17:58.126517Z","shell.execute_reply.started":"2022-05-26T15:17:27.540647Z","shell.execute_reply":"2022-05-26T15:17:58.125462Z"},"trusted":true},"execution_count":12,"outputs":[]}]}